{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterlevel stations\n",
    "Convert data from http://matroos.deltares.nl/timeseries/start/ (noos output) into a format that can be used in Google Fusiontable\n",
    "* Terschelling Noordzee (53.44248608°N, 005.33303479°E)\n",
    "* Delfzijl (53.32635727°E,6.93312255°N)\n",
    "* Haringvliet 10 (51.86313430°N, 3.86077225°E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(print station)? (<ipython-input-3-7272d5a3464a>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-7272d5a3464a>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print station\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(print station)?\n"
     ]
    }
   ],
   "source": [
    "def readCSVforFusionTable():\n",
    "    # Here keeping the source of Gerben's fnc.\n",
    "    stations = ['Terschelling','Delfzijl','Haringvliet']\n",
    "\n",
    "    for station in stations:\n",
    "        print station\n",
    "        df = pd.read_csv(r'D:\\hagenaar\\Documents\\EMODNET\\GLOSSISgrid\\ObservedWaterlevel' + str(station) + '.txt', \n",
    "                         skiprows=13, delimiter='  ', names=['time','waterlevel'])\n",
    "\n",
    "        df['time'] = pd.to_datetime(df['time'], yearfirst=True, format='%Y%m%d%H%M')\n",
    "        df.set_index('time', inplace=True)\n",
    "        df['waterlevel'][df['waterlevel'].isnull()] = np.nan\n",
    "        df['waterlevel'][df['waterlevel'] == 9999999] # missing value\n",
    "        df.dropna(inplace=True)\n",
    "        df.to_csv(r'D:\\hagenaar\\Documents\\EMODNET\\GLOSSISgrid\\ObservedWaterlevel' + str(station) + 'MODIFIED.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve data from $\\texttt{Matroos}$, but it works with indexes at the moment. By visiting the website and looking at the request, you read the code and perform the request, so that you do not need to download any file. Btw., pay attention to the printed header later in the loop, so that you are sure you are reading the right timeseries...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "listbuoys = {'terschelling noordzee': 297, 'harlingen': 6, 'nes': 321, 'delfzij': 1, 'haringvliet 10': 64}\n",
    "\n",
    "t0 = datetime.datetime(2015, 1, 1)\n",
    "tf = datetime.datetime(2018, 1, 1)\n",
    "\n",
    "tnow = datetime.datetime.now().isoformat().replace('T','+')\n",
    "tstart = t0.isoformat().replace('T','+') # start time\n",
    "tend = tf.isoformat().replace('T','+') # end time\n",
    "\n",
    "# function for subsequent lambda function\n",
    "def df_get_values(value, default):\n",
    "    if len(value.split())==2:\n",
    "        v = value.split()[1]\n",
    "    else:\n",
    "        v = default\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terschelling noordzee - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "terschelling noordzee - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "terschelling noordzee - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "terschelling noordzee - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "terschelling noordzee - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "terschelling noordzee - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "terschelling noordzee - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "terschelling noordzee - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "terschelling noordzee - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "terschelling noordzee - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "terschelling noordzee - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "terschelling noordzee - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "harlingen - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "harlingen - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "harlingen - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "harlingen - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "harlingen - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "harlingen - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "harlingen - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "harlingen - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "harlingen - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "harlingen - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "harlingen - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "harlingen - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "nes - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "nes - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "nes - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "nes - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "nes - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "nes - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "nes - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "nes - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "nes - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "nes - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "nes - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "nes - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "delfzij - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "delfzij - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "delfzij - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "delfzij - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "delfzij - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "delfzij - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "delfzij - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "delfzij - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "delfzij - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "delfzij - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "delfzij - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "delfzij - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n",
      "haringvliet 10 - from 2015-01-01+00:00:00 to 2015-04-01+00:00:00\n",
      "haringvliet 10 - from 2015-04-01+00:00:00 to 2015-07-01+00:00:00\n",
      "haringvliet 10 - from 2015-07-01+00:00:00 to 2015-10-01+00:00:00\n",
      "haringvliet 10 - from 2015-10-01+00:00:00 to 2016-01-01+00:00:00\n",
      "haringvliet 10 - from 2016-01-01+00:00:00 to 2016-04-01+00:00:00\n",
      "haringvliet 10 - from 2016-04-01+00:00:00 to 2016-07-01+00:00:00\n",
      "haringvliet 10 - from 2016-07-01+00:00:00 to 2016-10-01+00:00:00\n",
      "haringvliet 10 - from 2016-10-01+00:00:00 to 2017-01-01+00:00:00\n",
      "haringvliet 10 - from 2017-01-01+00:00:00 to 2017-04-01+00:00:00\n",
      "haringvliet 10 - from 2017-04-01+00:00:00 to 2017-07-01+00:00:00\n",
      "haringvliet 10 - from 2017-07-01+00:00:00 to 2017-10-01+00:00:00\n",
      "haringvliet 10 - from 2017-10-01+00:00:00 to 2018-01-01+00:00:00\n"
     ]
    }
   ],
   "source": [
    "cc = {}\n",
    "\n",
    "# This could take several minutes or hours for 6years, make it year by year to improve performance.\n",
    "\n",
    "for loc, loc_id0 in listbuoys.items():  # get water level signal for each buoy\n",
    "    c_df_tot = pd.DataFrame() # empty db\n",
    "    ti_dum = te_dum = t0\n",
    "    while ti_dum<tf:\n",
    "        te_dum = ti_dum + relativedelta(months=3) # add 3months\n",
    "        \n",
    "        # reconvert before request\n",
    "        ti_dum_text = ti_dum.isoformat().replace('T','+')\n",
    "        te_dum_text = te_dum.isoformat().replace('T','+')\n",
    "        \n",
    "        # in the following template,  loc_id0 is the location, source_newid0 is the \"observed\" type of source\n",
    "        additional_params = \"colors0=blue&localtime_offset=0&numser=1&old_unit_id0=1&oldlock_colors0=&oldlock_loc_id0=1&oldlock_source_newid0=1&oldlock_unit_id0=1&prealert=0&source_id0=10\"\n",
    "        url = (\"http://matroos.deltares.nl/timeseries/start/series.php?\"\n",
    "                            \"loc_id0=\" + str(loc_id0) + \"&\" # this is the location of the buoy\n",
    "                            \"source_newid0=10&\" # this is the source \"observed\"\n",
    "                            \"submit=Submit&\"\n",
    "                            \"tcurrent=\" + tnow + \"&\"\n",
    "                            \"tcurrent_new=\" + tnow + \"&\"\n",
    "                            \"tstart=\" + ti_dum_text + \"&\"\n",
    "                            \"tstop=\" + te_dum_text + \"&\"\n",
    "                            \"type=noos&\"\n",
    "                            \"unit_id0=1&\"\n",
    "                            \"alarm=0&\" # additional parameters from now on\n",
    "                            + additional_params)\n",
    "\n",
    "        r = requests.get(url).content\n",
    "        c = pd.read_csv(io.StringIO(r.decode('utf-8')),sep='\\t', header=0)\n",
    "        c_head = c[0:11]\n",
    "        # print(c_head[4:6]+'\\n') # query location, if needed\n",
    "        print(loc + ' - ' + 'from ' + ti_dum_text + ' to ' + te_dum_text)\n",
    "        c_cont = c[12:].reset_index(drop=True) # reset index\n",
    "\n",
    "        # get time and z from df\n",
    "        c_t = c_cont.applymap(lambda x: datetime.datetime(\n",
    "            int(x.split()[0][0:4]),\n",
    "            int(x.split()[0][4:6]),\n",
    "            int(x.split()[0][6:8]),\n",
    "            int(x.split()[0][8:10]),\n",
    "            int(x.split()[0][10:12])))\n",
    "        c_t.columns = ['Time']\n",
    "\n",
    "        c_z = c_cont.applymap(lambda x: df_get_values(x,np.NaN))\n",
    "        c_z.columns = ['WaterLevel']\n",
    "\n",
    "        c_df = c_t.join(c_z)\n",
    "        c_df_tot = c_df_tot.append(c_df)\n",
    "        \n",
    "        ti_dum = te_dum\n",
    "        \n",
    "    # dictionary of Dataframes\n",
    "    cc[loc] = c_df_tot # you can save it anywhere from here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dict of df's into several files [per location], csv format.\n",
    "for dfll_t, dfll_v in cc.items():\n",
    "    dfll_v.to_csv(os.path.join(PATH,dfll_t.replace(' ','_'))+'.csv', sep=',', index=False, na_rep='NaN')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
